---
phase: 28-scraper-service-backend
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - /Users/dweinbeck/Documents/brand-scraper/src/db/schema.ts
  - /Users/dweinbeck/Documents/brand-scraper/src/pipeline/context.ts
  - /Users/dweinbeck/Documents/brand-scraper/src/delivery/gcs.ts

autonomous: true

must_haves:
  truths:
    - "DB schema has gcsAssetsPrefix and assetsManifest columns on the jobs table"
    - "PipelineContext interface includes an onEvent callback for progress events"
    - "GCS helper can upload a single asset buffer to an individual object path"
    - "ProgressEvent and AssetsManifest types are defined and exported"
  artifacts:
    - path: "src/db/schema.ts"
      provides: "gcsAssetsPrefix column, assetsManifest JSONB column, ProgressEvent type, AssetsManifest type, extended PipelineMeta with events array"
      contains: "gcsAssetsPrefix"
    - path: "src/pipeline/context.ts"
      provides: "onEvent optional callback on PipelineContext interface"
      contains: "onEvent"
    - path: "src/delivery/gcs.ts"
      provides: "uploadAsset function for individual asset upload to GCS"
      exports: ["uploadAsset"]
  key_links:
    - from: "src/db/schema.ts"
      to: "drizzle migration"
      via: "drizzle-kit generate creates SQL migration from schema diff"
      pattern: "gcs_assets_prefix|assets_manifest"
    - from: "src/delivery/gcs.ts"
      to: "@google-cloud/storage"
      via: "singleton Storage instance"
      pattern: "storage\\.bucket.*\\.file.*\\.save"
---

<objective>
Add foundation types, DB schema columns, pipeline context extension, and GCS helper needed by all subsequent plans.

Purpose: Every other plan in Phase 28 depends on these types and infrastructure. DB migration must exist before any code writes to the new columns. The PipelineContext.onEvent callback is required before orchestrator can emit events. The uploadAsset GCS helper is required before handler can upload individual assets.

Output: Updated schema.ts with migration generated, extended context.ts with onEvent, extended gcs.ts with uploadAsset function.
</objective>

<execution_context>
@/Users/dweinbeck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dweinbeck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/Users/dweinbeck/Documents/personal-brand/.planning/ROADMAP.md
@/Users/dweinbeck/Documents/personal-brand/.planning/phases/28-scraper-service-backend/28-RESEARCH.md

IMPORTANT: This phase targets the brand-scraper repo at /Users/dweinbeck/Documents/brand-scraper/ (NOT the personal-brand repo). All file paths are relative to that repo. Run all commands from that directory.

Key source files to read before modifying:
@/Users/dweinbeck/Documents/brand-scraper/src/db/schema.ts
@/Users/dweinbeck/Documents/brand-scraper/src/pipeline/context.ts
@/Users/dweinbeck/Documents/brand-scraper/src/delivery/gcs.ts
@/Users/dweinbeck/Documents/brand-scraper/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add types, DB schema columns, and generate migration</name>
  <files>
    /Users/dweinbeck/Documents/brand-scraper/src/db/schema.ts
  </files>
  <action>
In /Users/dweinbeck/Documents/brand-scraper/src/db/schema.ts:

1. Add a ProgressEvent type (exported):
```typescript
export type ProgressEvent = {
  type: "pipeline_started" | "page_started" | "page_done" | "extract_done" |
        "asset_saved" | "asset_failed" | "assembly_done" | "pipeline_done";
  timestamp: string; // ISO 8601
  detail?: Record<string, unknown>;
};
```

2. Add an AssetsManifest type (exported):
```typescript
export type AssetManifestEntry = {
  category: string;      // "logos" | "favicons" | "og"
  filename: string;      // "primary.svg"
  originalUrl: string;   // source URL
  contentType: string;   // "image/svg+xml"
  sizeBytes: number;
  gcsObjectPath: string; // "jobs/{jobId}/assets/logos/primary.svg"
};

export type AssetsManifest = {
  assets: AssetManifestEntry[];
  totalCount: number;
  totalSizeBytes: number;
  createdAt: string; // ISO timestamp
};
```

3. Extend the PipelineMeta type to include events:
```typescript
export type PipelineMeta = {
  stages?: Array<{ stage: string; status: string; duration_ms: number }>;
  pages_sampled?: number;
  duration_ms?: number;
  events?: ProgressEvent[]; // NEW
};
```

4. Add two new columns to the jobs table definition (AFTER gcsAssetsZipUri, BEFORE webhookStatus):
```typescript
/** GCS path prefix for individual assets (e.g., jobs/{jobId}/assets/) */
gcsAssetsPrefix: text("gcs_assets_prefix"),

/** Assets manifest with metadata for all uploaded assets */
assetsManifest: jsonb("assets_manifest").$type<AssetsManifest>(),
```

5. Run migration generation from the brand-scraper directory:
```bash
cd /Users/dweinbeck/Documents/brand-scraper && npx drizzle-kit generate
```

This should create a new migration file (0002_*.sql) with ALTER TABLE statements adding the two columns.

IMPORTANT: Do NOT remove or modify the existing gcsAssetsZipUri column. It will be reused for on-demand zip URI storage.
  </action>
  <verify>
1. `cd /Users/dweinbeck/Documents/brand-scraper && npx tsc --noEmit` passes (types compile)
2. A new migration file exists in /Users/dweinbeck/Documents/brand-scraper/drizzle/ matching pattern 0002_*.sql
3. The migration SQL contains: ALTER TABLE "jobs" ADD COLUMN "gcs_assets_prefix" text; ALTER TABLE "jobs" ADD COLUMN "assets_manifest" jsonb;
4. ProgressEvent, AssetsManifest, AssetManifestEntry types are exported from schema.ts
  </verify>
  <done>
- PipelineMeta type includes optional events array of ProgressEvent[]
- ProgressEvent type exported with 8 event types
- AssetsManifest and AssetManifestEntry types exported
- jobs table has gcsAssetsPrefix (text) and assetsManifest (jsonb) columns
- Migration file generated and ready to apply
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend PipelineContext with onEvent callback and add uploadAsset to GCS helper</name>
  <files>
    /Users/dweinbeck/Documents/brand-scraper/src/pipeline/context.ts
    /Users/dweinbeck/Documents/brand-scraper/src/delivery/gcs.ts
  </files>
  <action>
**In /Users/dweinbeck/Documents/brand-scraper/src/pipeline/context.ts:**

1. Import the ProgressEvent type from the db schema:
```typescript
import type { ProgressEvent } from "../db/schema.js";
```

2. Add an optional onEvent callback to the PipelineContext interface:
```typescript
/** Optional callback for emitting progress events. Set by handler, called by pipeline stages. */
onEvent?: (event: ProgressEvent) => Promise<void>;
```

This keeps the pipeline DB-agnostic -- the handler will provide the implementation that persists to DB.

**In /Users/dweinbeck/Documents/brand-scraper/src/delivery/gcs.ts:**

1. Add a new exported function `uploadAsset` that uploads a single buffer to a specific GCS path:
```typescript
/**
 * Upload a single asset to GCS under the job's assets directory.
 *
 * @param bucketName - GCS bucket name
 * @param jobId - Job ID (used as path prefix)
 * @param category - Asset category ("logos" | "favicons" | "og")
 * @param filename - Asset filename (e.g., "primary.svg")
 * @param buffer - File content as Buffer
 * @param contentType - MIME type for the uploaded object
 * @returns Object with gcsUri (gs:// URI) and objectPath (relative path in bucket)
 */
export async function uploadAsset(
  bucketName: string,
  jobId: string,
  category: string,
  filename: string,
  buffer: Buffer,
  contentType: string,
): Promise<{ gcsUri: string; objectPath: string }> {
  const objectPath = `jobs/${jobId}/assets/${category}/${filename}`;
  const bucket = storage.bucket(bucketName);
  const file = bucket.file(objectPath);
  await file.save(buffer, { contentType, resumable: false });
  return {
    gcsUri: `gs://${bucketName}/${objectPath}`,
    objectPath,
  };
}
```

2. Also add a `createOnDemandZip` function (will be used by Plan 04, but belongs in this GCS module):
```typescript
import archiver from "archiver";

/**
 * Create a ZIP of all job assets from GCS and upload it back to GCS.
 * Streams archiver output directly to a GCS write stream (no in-memory buffer).
 * Includes brand.json in the zip root.
 *
 * @param bucketName - GCS bucket name
 * @param jobId - Job ID
 * @param assetPaths - Array of GCS object paths to include in the zip
 * @param signedUrlExpiryMs - Expiry for the returned signed URL
 * @returns Object with zipUri (gs:// URI) and signedUrl
 */
export async function createOnDemandZip(
  bucketName: string,
  jobId: string,
  assetPaths: Array<{ gcsObjectPath: string; category: string; filename: string }>,
  signedUrlExpiryMs: number = DEFAULT_SIGNED_URL_EXPIRY_MS,
): Promise<{ zipUri: string; signedUrl: string }> {
  const bucket = storage.bucket(bucketName);
  const zipPath = `jobs/${jobId}/assets.zip`;
  const zipFile = bucket.file(zipPath);

  const writeStream = zipFile.createWriteStream({
    contentType: "application/zip",
    resumable: false,
  });

  const archive = archiver("zip", { zlib: { level: 6 } });

  const done = new Promise<void>((resolve, reject) => {
    writeStream.on("finish", resolve);
    writeStream.on("error", reject);
    archive.on("error", reject);
  });

  archive.pipe(writeStream);

  // Add each asset from GCS
  for (const asset of assetPaths) {
    const file = bucket.file(asset.gcsObjectPath);
    const [buffer] = await file.download();
    archive.append(buffer, { name: `${asset.category}/${asset.filename}` });
  }

  // Also add brand.json if it exists
  const brandFile = bucket.file(`jobs/${jobId}/brand.json`);
  try {
    const [brandBuffer] = await brandFile.download();
    archive.append(brandBuffer, { name: "brand.json" });
  } catch {
    // brand.json may not exist for failed jobs -- skip
  }

  await archive.finalize();
  await done;

  // Generate signed URL for the zip
  const [signedUrl] = await zipFile.getSignedUrl({
    version: "v4",
    action: "read",
    expires: Date.now() + signedUrlExpiryMs,
  });

  return {
    zipUri: `gs://${bucketName}/${zipPath}`,
    signedUrl,
  };
}
```

Add the archiver import at the top of gcs.ts alongside the existing Storage import.

IMPORTANT: Do NOT modify the existing `uploadResults` or `generateSignedUrl` functions. They must continue working exactly as they are (brand_json_url regression protection).
  </action>
  <verify>
1. `cd /Users/dweinbeck/Documents/brand-scraper && npx tsc --noEmit` passes
2. PipelineContext interface includes onEvent field
3. uploadAsset and createOnDemandZip are exported from gcs.ts
4. Existing uploadResults and generateSignedUrl functions remain unchanged
  </verify>
  <done>
- PipelineContext has optional onEvent callback typed with ProgressEvent
- uploadAsset function uploads a single buffer to jobs/{jobId}/assets/{category}/{filename}
- createOnDemandZip function streams zip from GCS objects to GCS, returns signed URL
- Existing GCS functions untouched (no regression risk)
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `cd /Users/dweinbeck/Documents/brand-scraper && npx tsc --noEmit`
2. Migration file exists: `ls /Users/dweinbeck/Documents/brand-scraper/drizzle/0002_*`
3. All new types importable: ProgressEvent, AssetsManifest, AssetManifestEntry from schema.ts
4. All new functions importable: uploadAsset, createOnDemandZip from gcs.ts
5. Existing tests still pass: `cd /Users/dweinbeck/Documents/brand-scraper && npm test`
</verification>

<success_criteria>
- DB schema extended with 2 new columns + migration generated
- 3 new types exported (ProgressEvent, AssetsManifest, AssetManifestEntry)
- PipelineMeta extended with events array
- PipelineContext extended with onEvent callback
- 2 new GCS functions (uploadAsset, createOnDemandZip)
- Zero changes to existing uploadResults/generateSignedUrl functions
- TypeScript compiles, existing tests pass
</success_criteria>

<output>
After completion, create `/Users/dweinbeck/Documents/personal-brand/.planning/phases/28-scraper-service-backend/28-01-SUMMARY.md`
</output>
