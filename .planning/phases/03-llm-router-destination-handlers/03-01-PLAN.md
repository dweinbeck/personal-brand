---
phase: 03-llm-router-destination-handlers
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/gsd/router.ts
  - src/lib/gsd/schemas.ts
  - src/lib/gsd/capture.ts
  - src/app/api/gsd/capture/route.ts
  - src/app/api/gsd/capture/screenshot/route.ts
autonomous: true
requirements:
  - ROUTE-SCHEMA
  - ROUTE-CLASSIFY
  - ROUTE-PIPELINE

must_haves:
  truths:
    - "routingOutputSchema defines category (github_issue|task|inbox|unknown), title, summary, priority, and confidence fields"
    - "classifyCapture calls generateText with Output.object and Gemini 2.0 Flash"
    - "classifyCapture returns structured routing result with confidence score"
    - "processCapture orchestrates: mark processing → classify → route by category → mark routed/failed"
    - "Confidence below 0.7 forces routing to inbox regardless of classified category"
    - "unknown category routes to inbox"
    - "processCapture is fire-and-forget (called with .catch(console.error) from capture routes)"
    - "Both capture routes call processCapture after saving"
    - "npm run build succeeds with zero type errors"
    - "npm run lint passes"
  artifacts:
    - path: "src/lib/gsd/router.ts"
      provides: "LLM classification and async routing pipeline"
      exports: ["classifyCapture", "processCapture", "routingOutputSchema"]
    - path: "src/lib/gsd/schemas.ts"
      provides: "Extended with routing output schema"
      exports: ["routingOutputSchema", "RoutingOutput"]
    - path: "src/lib/gsd/capture.ts"
      provides: "Extended with getCapture for reading back capture data"
      exports: ["getCapture"]
  key_links:
    - from: "src/lib/gsd/router.ts"
      to: "ai"
      via: "import generateText, Output"
      pattern: "import.*generateText.*Output.*from.*ai"
    - from: "src/lib/gsd/router.ts"
      to: "@ai-sdk/google"
      via: "import google"
      pattern: "import.*google.*from.*@ai-sdk/google"
    - from: "src/app/api/gsd/capture/route.ts"
      to: "src/lib/gsd/router.ts"
      via: "import processCapture"
      pattern: "import.*processCapture.*from.*router"
---

<objective>
Create the LLM routing schema, classification prompt with few-shot examples, and async processing pipeline. This plan establishes the core intelligence layer that classifies captures and decides where they should be routed.

Purpose: Without this, captures sit in "pending" status forever. This plan adds the brain that reads each capture and decides: GitHub Issue? Task? Builder Inbox?

Output: router.ts (new), schemas.ts (extended), capture.ts (extended), both capture routes (updated to call processCapture).
</objective>

<execution_context>
@/Users/dweinbeck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dweinbeck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/lib/gsd/schemas.ts
@src/lib/gsd/capture.ts
@src/app/api/gsd/capture/route.ts
@src/app/api/gsd/capture/screenshot/route.ts
@src/lib/research-assistant/model-client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add routing output schema and getCapture helper</name>
  <files>
    src/lib/gsd/schemas.ts
    src/lib/gsd/capture.ts
  </files>
  <action>
    **1a. Extend `src/lib/gsd/schemas.ts` — add routing output schema:**

    Add after the existing `captureDestinationSchema`:

    ```typescript
    // -- LLM routing output schema ------------------------------------------------

    export const routingCategorySchema = z.enum([
      "github_issue",
      "task",
      "inbox",
      "unknown",
    ]);

    export type RoutingCategory = z.infer<typeof routingCategorySchema>;

    export const routingOutputSchema = z.object({
      category: routingCategorySchema.describe(
        "Where to route this capture: github_issue for bugs/features/code changes, task for personal todos/reminders, inbox for unclear items, unknown if cannot classify"
      ),
      title: z.string().describe("Short title for the routed item (under 100 chars)"),
      summary: z.string().describe("1-3 sentence summary of what needs to be done"),
      priority: z.enum(["high", "medium", "low"]).describe("Urgency level"),
      confidence: z.number().min(0).max(1).describe("How confident the classification is (0-1)"),
    });

    export type RoutingOutput = z.infer<typeof routingOutputSchema>;
    ```

    **1b. Extend `src/lib/gsd/capture.ts` — add getCapture helper:**

    Add after `updateCaptureStatus`:

    ```typescript
    /**
     * Read a capture document by ID.
     * Returns the document data or null if not found.
     */
    export async function getCapture(
      id: string,
    ): Promise<(CaptureInput & { status: string; context?: string }) | null> {
      const doc = await capturesCol().doc(id).get();
      if (!doc.exists) return null;
      return doc.data() as CaptureInput & { status: string; context?: string };
    }
    ```
  </action>
  <verify>
    1. `npm run build` succeeds
    2. `npm run lint` passes
    3. Verify routingOutputSchema has all 5 fields with `.describe()` annotations
    4. Verify getCapture returns null for missing docs
  </verify>
  <done>
    - routingOutputSchema exported with category, title, summary, priority, confidence
    - routingCategorySchema includes "unknown" escape hatch
    - getCapture reads back capture documents for the routing pipeline
  </done>
</task>

<task type="auto">
  <name>Task 2: Create LLM router with classification prompt and processing pipeline</name>
  <files>
    src/lib/gsd/router.ts
  </files>
  <action>
    **Create `src/lib/gsd/router.ts`:**

    ```typescript
    import { generateText, Output } from "ai";
    import { google } from "@ai-sdk/google";
    import { getCapture, updateCaptureStatus } from "./capture";
    import { routingOutputSchema, type RoutingOutput } from "./schemas";

    const CONFIDENCE_THRESHOLD = 0.7;

    const ROUTING_PROMPT = `You are a routing classifier for a solo developer's Builder OS capture system.

    Classify the captured input into one of these categories:
    - github_issue: Bug reports, feature requests, code changes, technical debt, refactoring ideas, anything that should become a GitHub issue on a software project
    - task: Personal todos, reminders, non-code action items, scheduling, follow-ups, purchases, errands
    - inbox: Items that need human review — ambiguous, multi-part, or could go either way
    - unknown: Cannot determine intent from the input

    Context: This is a personal productivity tool. The developer captures ideas via voice dictation or screenshots from their iPhone. Captures are typically short, informal, and action-oriented.

    Few-shot examples:

    Input: "The brand scraper is returning empty rectangles for some SVG logos, need to add a fallback that converts them to PNG first"
    → category: github_issue, title: "Brand scraper: add PNG fallback for empty SVG rectangles", priority: medium, confidence: 0.95

    Input: "Remember to buy new AirPods Pro tips this weekend"
    → category: task, title: "Buy AirPods Pro tips", priority: low, confidence: 0.92

    Input: "I think we should restructure the whole navigation but also maybe add a dark mode toggle and fix that weird scrolling bug on mobile"
    → category: inbox, title: "Navigation restructure + dark mode + mobile scroll bug", priority: medium, confidence: 0.55

    Input: "The contact form validation is broken when you submit with an empty email field, it shows a 500 instead of a validation error"
    → category: github_issue, title: "Contact form: 500 error on empty email submission", priority: high, confidence: 0.97

    Input: "Schedule dentist appointment for next Tuesday"
    → category: task, title: "Schedule dentist appointment - next Tuesday", priority: medium, confidence: 0.94

    Now classify this capture:`;

    /**
     * Classify a capture using Gemini 2.0 Flash.
     * Returns structured routing output with confidence score.
     */
    export async function classifyCapture(
      transcript: string,
      context?: string,
    ): Promise<RoutingOutput> {
      const input = context
        ? `Input: "${transcript}"\nAdditional context: "${context}"`
        : `Input: "${transcript}"`;

      const { output } = await generateText({
        model: google("gemini-2.0-flash"),
        output: Output.object({ schema: routingOutputSchema }),
        prompt: `${ROUTING_PROMPT}\n\n${input}`,
      });

      if (!output) {
        // LLM returned no structured output — fallback to inbox
        return {
          category: "unknown",
          title: transcript.slice(0, 100),
          summary: transcript,
          priority: "medium",
          confidence: 0,
        };
      }

      return output;
    }

    /**
     * Route to the appropriate destination based on classification.
     * Returns the destination ref (issue URL, task ID, or "inbox").
     */
    async function routeToDestination(
      captureId: string,
      routing: RoutingOutput,
    ): Promise<{ destination: string; destinationRef: string }> {
      const effectiveCategory =
        routing.confidence < CONFIDENCE_THRESHOLD || routing.category === "unknown"
          ? "inbox"
          : routing.category;

      switch (effectiveCategory) {
        case "github_issue": {
          // Phase 3, Plan 2 will implement this
          const { routeToGitHub } = await import("./destinations/github");
          const issueUrl = await routeToGitHub(routing);
          return { destination: "github_issue", destinationRef: issueUrl };
        }
        case "task": {
          // Phase 3, Plan 3 will implement this
          const { routeToTask } = await import("./destinations/tasks");
          const taskId = await routeToTask(routing);
          return { destination: "task", destinationRef: taskId };
        }
        case "inbox":
        default:
          return { destination: "inbox", destinationRef: "inbox" };
      }
    }

    /**
     * Full async processing pipeline for a capture.
     * Called fire-and-forget from capture API routes.
     *
     * Flow: mark processing → classify with LLM → route → mark routed/failed
     */
    export async function processCapture(captureId: string): Promise<void> {
      try {
        // 1. Mark as processing
        await updateCaptureStatus(captureId, { status: "processing" });

        // 2. Read capture data
        const capture = await getCapture(captureId);
        if (!capture) {
          throw new Error(`Capture ${captureId} not found`);
        }

        // 3. Build input text from capture
        const transcript =
          capture.type === "dictation"
            ? capture.transcript ?? ""
            : capture.context ?? "[Screenshot capture — no transcript]";

        // 4. Classify with LLM
        const routing = await classifyCapture(transcript, capture.context);

        // 5. Route to destination
        const { destination, destinationRef } = await routeToDestination(
          captureId,
          routing,
        );

        // 6. Mark as routed
        await updateCaptureStatus(captureId, {
          status: "routed",
          routingResult: routing as unknown as Record<string, unknown>,
          destination,
          destinationRef,
        });
      } catch (err) {
        // Mark as failed with error message
        const errorMessage =
          err instanceof Error ? err.message : "Unknown error";
        console.error(`Capture ${captureId} processing failed:`, errorMessage);

        try {
          await updateCaptureStatus(captureId, {
            status: "failed",
            error: errorMessage,
          });
        } catch (updateErr) {
          console.error(
            `Failed to update capture ${captureId} status:`,
            updateErr,
          );
        }
      }
    }
    ```

    **Key design decisions:**
    - Dynamic `import()` for destination handlers — avoids loading GitHub/Tasks deps when not needed and allows Plan 2 and Plan 3 to add these files independently
    - Confidence threshold (0.7) gates all routing — below threshold always goes to inbox
    - Full error capture with status machine: pending → processing → routed/failed
    - LLM null output fallback returns "unknown" with confidence 0 (routes to inbox)
  </action>
  <verify>
    1. `npm run build` succeeds
    2. `npm run lint` passes
    3. Verify router.ts imports from "ai" and "@ai-sdk/google"
    4. Verify CONFIDENCE_THRESHOLD is 0.7
    5. Verify processCapture handles errors and updates status to "failed"
  </verify>
  <done>
    - classifyCapture uses generateText + Output.object with Gemini 2.0 Flash
    - processCapture orchestrates full pipeline with error handling
    - routeToDestination applies confidence threshold and routes accordingly
    - Dynamic imports for destination handlers (Plan 2 and 3 will create them)
  </done>
</task>

<task type="auto">
  <name>Task 3: Wire processCapture into both capture API routes</name>
  <files>
    src/app/api/gsd/capture/route.ts
    src/app/api/gsd/capture/screenshot/route.ts
  </files>
  <action>
    **3a. Update `src/app/api/gsd/capture/route.ts`:**

    Add import at top:
    ```typescript
    import { processCapture } from "@/lib/gsd/router";
    ```

    Replace the comment placeholder (line ~42-43):
    ```typescript
    // 5. Async processing placeholder (Phase 3 will add LLM routing here)
    // processCapture(captureId).catch(console.error);
    ```

    With:
    ```typescript
    // 5. Fire-and-forget async processing (LLM classification + routing)
    processCapture(captureId).catch(console.error);
    ```

    **3b. Update `src/app/api/gsd/capture/screenshot/route.ts`:**

    Add import at top:
    ```typescript
    import { processCapture } from "@/lib/gsd/router";
    ```

    Replace the comment placeholder (line ~89-90):
    ```typescript
    // 9. Async processing placeholder (Phase 3 will add LLM routing here)
    // processCapture(captureId).catch(console.error);
    ```

    With:
    ```typescript
    // 9. Fire-and-forget async processing (LLM classification + routing)
    processCapture(captureId).catch(console.error);
    ```
  </action>
  <verify>
    1. `npm run build` succeeds
    2. `npm run lint` passes
    3. Both routes import and call processCapture
    4. processCapture is called with `.catch(console.error)` (fire-and-forget)
  </verify>
  <done>
    - Both capture routes now trigger async LLM processing after save
    - Fire-and-forget pattern preserves <5s response time for iPhone Shortcuts
    - No change to the 202 Accepted response — processing happens in background
  </done>
</task>

</tasks>

<verification>
1. `npm run lint` — zero errors
2. `npm run build` — zero errors, all new modules type-check
3. `npm test` — all existing tests pass (no regression)
4. Manual check: router.ts uses generateText + Output.object (not deprecated generateObject)
5. Manual check: CONFIDENCE_THRESHOLD = 0.7, below threshold routes to inbox
6. Manual check: Both capture routes call processCapture fire-and-forget
</verification>

<success_criteria>
- LLM routing pipeline classifies captures using Gemini 2.0 Flash
- Confidence threshold (0.7) gates routing decisions
- processCapture handles full lifecycle: processing → routed/failed
- Both capture endpoints trigger async processing
- Dynamic imports for destination handlers (Plan 2/3 create them)
- Build, lint, and test all pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-router-destination-handlers/03-01-SUMMARY.md`
</output>
